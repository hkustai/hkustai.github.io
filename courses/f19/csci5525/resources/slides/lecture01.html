<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="Machine Learning (CSCI 5525)">
  <meta name="dcterms.date" content="2019-09-03">
  <title>Lecture 01</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../assets/custom-js/reveal.js//css/reset.css">
  <link rel="stylesheet" href="../../assets/custom-js/reveal.js//css/reveal.css">
  <style>
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <link rel="stylesheet" href="../../assets/custom-js/reveal.js//css/theme/solarized.css" id="theme">
  <!-- Printing and PDF exports -->
  <script>
    var link = document.createElement( 'link' );
    link.rel = 'stylesheet';
    link.type = 'text/css';
    link.href = window.location.search.match( /print-pdf/gi ) ? '../../assets/custom-js/reveal.js//css/print/pdf.css' : '../../assets/custom-js/reveal.js//css/print/paper.css';
    document.getElementsByTagName( 'head' )[0].appendChild( link );
  </script>
  <!--[if lt IE 9]>
  <script src="../../assets/custom-js/reveal.js//lib/js/html5shiv.js"></script>
  <![endif]-->
  <script src="../../assets/custom-js/katex/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
    var mathElements = document.getElementsByClassName("math");
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") { katex.render(texText.data, mathElements[i], { displayMode: mathElements[i].classList.contains("display"), throwOnError: false } );
    }}});</script>
  <link rel="stylesheet" href="../../assets/custom-js/katex/katex.min.css" />
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section id="title-slide">
  <h1 class="title">Lecture 01</h1>
  <p class="author">Machine Learning (CSCI 5525)</p>
  <p class="date">September 3, 2019</p>
</section>

<section><section id="general-information" class="title-slide slide level1"><h1>General Information</h1></section><section id="logistics" class="slide level2">
<h2>Logistics</h2>
<ul>
<li><strong>Course</strong>: CSCI 5525, Fall 2019</li>
<li><strong>Location</strong>: Mechanical Engineering 108</li>
<li><strong>Time</strong>: Tuesdays and Thursdays, 11:15 AM‑12:30 PM</li>
<li><strong>Course webpage</strong>: <a href="https://zstevenwu.com/courses/f19/csci5525/" class="uri">https://zstevenwu.com/courses/f19/csci5525/</a></li>
<li><strong>Canvas</strong>: you should be registered on it now
<ul>
<li><em>Please pay close attention to Course webpage and Canvas during the semester! Things might change.</em></li>
</ul></li>
</ul>
</section><section id="instructor" class="slide level2">
<h2>Instructor</h2>
<ul>
<li>Steven Wu
<ul>
<li><strong>Webpage</strong>: <a href="https://zstevenwu.com" class="uri">https://zstevenwu.com</a></li>
<li><strong>Email</strong>: zsw@umn.edu</li>
<li><strong>Office hour</strong>: 4:00-5:00 pm on Tues
<ul>
<li>Might add one more office hour if needed</li>
</ul></li>
<li><strong>Location</strong>: Keller Hall 6-225E</li>
</ul></li>
</ul>
</section><section id="teaching-assistants" class="slide level2">
<h2>Teaching Assistants:</h2>
<ul>
<li>Arun Kumar
<ul>
<li><strong>Email</strong>: kumar250@umn.edu</li>
<li><strong>Office</strong> hour: N/A</li>
</ul></li>
<li>Xinyi Wang
<ul>
<li><strong>Email</strong>: wang4831@umn.edu</li>
<li><strong>Office hour</strong>: N/A</li>
</ul></li>
<li>Please treat them nicely</li>
</ul>
</section><section id="communication" class="slide level2">
<h2>Communication</h2>
<ul>
<li><p><strong>Canvas</strong>: We will be using Canvas for all assignments and grades.</p></li>
<li><p>Please also post all questions on <strong>Canvas</strong> as discussions instead of sending emails.</p></li>
<li><p><strong>Email</strong> (less preferred): If you email your instructor, you must include the substring “CSCI 5525” to begin a meaningful subject line and have tried to resolve the issue appropriately otherwise. Please use your UMN email account.</p></li>
</ul>
</section><section id="emails-for-homework-regrade" class="slide level2">
<h2>Emails for Homework Regrade</h2>
<ul>
<li><strong>Regrade request</strong>: contact the TA who actually grades that problem.
<ul>
<li>Grading assignment will be announced.</li>
</ul></li>
</ul>
</section><section id="unite" class="slide level2">
<h2>UNITE</h2>
<ul>
<li>Video lectures will be recorded and available, with delays for on-campus students.</li>
<li><strong>Please do not download and distribute the videos!</strong>
<ul>
<li>Against UMN policies.</li>
</ul></li>
<li>Homework submissions via Canvas.</li>
</ul>
</section><section id="enrollment" class="slide level2">
<h2>Enrollment</h2>
<ul>
<li><p>If you are not on the waitlist, put down your info at this Google form <a href="https://forms.gle/6PGVgatMfQZEARwE7" class="uri">https://forms.gle/6PGVgatMfQZEARwE7</a></p></li>
<li><p>Link will be on the course webpage.</p></li>
</ul>
</section></section>
<section><section id="organization" class="title-slide slide level1"><h1>Organization</h1></section><section id="midterm-and-final-exam" class="slide level2">
<h2>Midterm and Final exam</h2>
<ul>
<li><p>The midterm exam will be held during a regular class slot. It will be a written test. Tentative date 10/17</p></li>
<li><p>The final exam date will be announced during the semester. (Format: take-home or in-class)</p></li>
</ul>
</section><section id="homeworks" class="slide level2">
<h2>Homeworks</h2>
<ul>
<li>Five homeworks with both written and programming components.</li>
<li>Late homeworks will <strong>not</strong> accepted. <strong>No grace days!</strong></li>
<li>Your <strong>lowest</strong> homework score will be dropped.</li>
<li><strong>Collaboration policy</strong>: you can discuss with other students about the homework, but you must write up and code up the solutions on your own! You also must mention the names of the students you discuss with.</li>
</ul>
</section><section id="homework-written-components" class="slide level2">
<h2>Homework: Written components</h2>
<ul>
<li><p>Derivation and understanding of the algorithms</p></li>
<li><p>Submission guidelines:</p>
<ul>
<li><strong>All submissions in pdf</strong> Please type up your written homeworks using <a href="https://www.latex-project.org/">LaTeX</a>.
<ul>
<li><em>LaTeX is a high-quality typesetting system.</em></li>
</ul></li>
<li>We will set up <a href="https://www.overleaf.com/">OverLeaf</a> templates.
<ul>
<li>Very easy to use!</li>
</ul></li>
</ul></li>
</ul>
</section><section id="homework-programming-components" class="slide level2">
<h2>Homework: Programming components</h2>
<ul>
<li>All programming in <strong>Python</strong>. Please get familiar with:
<ul>
<li>Python3</li>
<li>Python Notebook (Jupyter)</li>
</ul></li>
<li><strong>Installation</strong>: We are currently exploring options, we will provide one of the following
<ul>
<li>a <a href="https://www.virtualbox.org/">VirtualBox</a> virtual environment with all of the packages pre-installed</li>
<li><a href="https://colab.research.google.com/">Google Colab</a></li>
</ul></li>
<li>Computing resources:
<ul>
<li><a href="https://vole.cse.umn.edu">UMN Virtual Online Linux Environment</a></li>
</ul></li>
</ul>
</section><section id="grading-policy" class="slide level2">
<h2>Grading policy</h2>
<ul>
<li>Homework 60% (15% for each homework)</li>
<li>Midterm 15%</li>
<li>Final 20%</li>
<li>Class Participation 5%</li>
</ul>
</section><section id="pre-requisite" class="slide level2">
<h2>Pre-requisite</h2>
<ul>
<li>Ideally you will have completed
<ul>
<li>CSCI 5521 or equivalently other introduction to machine learning courses</li>
<li>undergraduate level training or coursework in linear algebra, multivariate calculus, and basic probability and statistics</li>
</ul></li>
</ul>
</section><section id="technical-background" class="slide level2">
<h2>Technical background</h2>
<ul>
<li>You should know:
<ul>
<li>linear algebra</li>
<li>probability</li>
<li>calculus</li>
<li>basic understandings of algorithms design (e.g. big-<span class="math inline">O</span>, <span class="math inline">\Omega</span> notation)</li>
<li>how to prove mathematical claims formally</li>
<li>programming skills with Python</li>
</ul></li>
</ul>
</section></section>
<section><section id="topics" class="title-slide slide level1"><h1>Topics</h1></section><section id="what-is-ml" class="slide level2">
<h2>What is ML?</h2>
<ul>
<li><em>“Machine learning (ML) is the scientific study of algorithms and statistical models that computer systems use to perform a specific task without using explicit instructions, relying on patterns and inference instead.”</em> — Wikipedia Page on Machine Learning</li>
</ul>
</section><section id="supervised-learning" class="slide level2">
<h2>Supervised learning</h2>
<p><strong>Labeled examples</strong>: <span class="math inline">(x_1, y_1), (x_2, y_2), \ldots (x_n, y_n)</span></p>
<ul>
<li><p>each <span class="math inline">x_i</span> is a <em>feature vector</em> (or representation) of an <em>instance</em> (e.g. image, audio, medical record)</p></li>
<li><p>each <span class="math inline">y_i</span> is a task-specific <em>label</em> (e.g. cats versus dogs images, male versus female voices, risk of lung cancer)</p></li>
</ul>
<p><strong>Goal</strong>: learn a <em>predictor</em> <span class="math inline">\hat f\colon X \rightarrow Y</span> based on labeled examples, that accurately <em>predicts</em> the labels of future instances.</p>
</section><section id="supervised-learning-topics" class="slide level2">
<h2>Supervised learning topics</h2>
<ul>
<li>Linear regression</li>
<li>Logistic regression</li>
<li>Support vector machines
<ul>
<li>Constrained optimization, Lagrangian duality</li>
<li>Margin maximization</li>
</ul></li>
<li>Non-linear methods: kernels</li>
<li>Neural networks
<ul>
<li>Optimization: (Stochastic) gradient descent</li>
</ul></li>
</ul>
</section><section id="probably-skipping" class="slide level2">
<h2>Probably skipping</h2>
<ul>
<li>Decision trees</li>
<li>Nearest neighbors</li>
<li>Naive Bayes</li>
<li>other stuff you might have seen in CSCI5521</li>
<li><em>We will not cover the cutting edge of deep learning. We plan to offer a new course dedicated to deep learning in Spring 2020.</em></li>
</ul>
</section><section id="the-problem-of-over-fitting" class="slide level2">
<h2>The problem of over-fitting</h2>
<ul>
<li>Suppose we observe data <span class="math inline">(x_1, y_1),\ldots , (x_n, y_n)</span> drawn from a distribution.</li>
<li>Train the following predictor: <span class="math display">\hat f(X)= \begin{cases} y_i, &amp; \text{if}\ X=x_i \\ \text{&quot;Gopher!&quot;},
  &amp; \text{otherwise} \end{cases}</span></li>
</ul>
</section><section id="over-fitting" class="slide level2">
<h2>Over-fitting</h2>
<ul>
<li><span class="math inline">\hat f</span> has training error = 0, but errs on every example it hasn’t seen.
<ul>
<li>Well, except for Gopher.</li>
</ul></li>
<li>How do we formally study this phenomenon?</li>
</ul>
</section><section id="machine-learning-theory" class="slide level2">
<h2>Machine learning theory</h2>
<ul>
<li>Formulation of learning
<ul>
<li>PAC learning model</li>
<li>Empirical risk minimization</li>
</ul></li>
<li>Generalization
<ul>
<li>Complexity measures of function classes
<ul>
<li>VC dimension</li>
<li>Rademacher complexity</li>
</ul></li>
<li>Maybe: stability of learning algorithms</li>
</ul></li>
<li>Tools: concentration of measure
<ul>
<li>Chernoff bounds</li>
<li>Moment generating functions</li>
</ul></li>
</ul>
</section><section id="ensemble-methods" class="slide level2">
<h2>Ensemble methods</h2>
<p>Turning <em>weak</em> learners into <em>strong</em> learners.</p>
<ul>
<li>Boosting method
<ul>
<li>Adaboost</li>
</ul></li>
<li>Bagging = Bootstrap aggregating
<ul>
<li>Random Forest</li>
</ul></li>
</ul>
</section><section id="generative-models" class="slide level2">
<h2>Generative models</h2>
<ul>
<li>Variational Autoencoders (VAE)</li>
<li>Generative adversarial nets (GANs)</li>
</ul>
</section><section id="interactive-learning" class="slide level2">
<h2>Interactive learning</h2>
<ul>
<li>Online learning
<ul>
<li>sequential decision-making (with full info)</li>
<li>e.g. traffic routing, portfolio optimization</li>
</ul></li>
<li>Multi-armed bandit learning
<ul>
<li>one-sided feedback</li>
<li>exploration versus exploitation</li>
<li>e.g. clinical trials, online advertising, contents recommendation</li>
</ul></li>
<li>Reinforcement learning
<ul>
<li>learner interacts with the environment</li>
<li>e.g. video games, educational software, healthcare decision making, robotics or people-facing applications</li>
</ul></li>
</ul>
</section><section id="additional-topics-tentative" class="slide level2">
<h2>Additional topics (tentative)</h2>
<ul>
<li><p>Privacy-preserving machine learning</p>
<ul>
<li>when the data has sensitive info</li>
</ul></li>
<li><p>Fairness in machine learning</p>
<ul>
<li>when algorithms inform or make decisions on people</li>
</ul></li>
<li><p>Machine learning and game theory</p></li>
<li><p>Probabilistic programming</p>
<ul>
<li>design of programming language for ML</li>
</ul></li>
</ul>
</section><section id="readings" class="slide level2">
<h2>Readings</h2>
<ul>
<li>Most lectures are paired with a reading.</li>
<li>These are <em>optional</em> and classes will not exactly follow the readings, but you will get more out of the lectures if you skim the readings beforehand (or afterwards).</li>
</ul>
</section><section id="books" class="slide level2">
<h2>Books:</h2>
<ul>
<li><strong>CML</strong>: <a href="http://ciml.info/">A Course in Machine Learning</a>
<ul>
<li>by Hal Daumé III</li>
</ul></li>
<li><strong>UML</strong>: <a href="https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/">Understanding Machine Learning: From Theory to Algorithms</a>
<ul>
<li>by Shai Shalev-Shwartz and Shai Ben-David</li>
</ul></li>
<li><strong>MLaPP</strong>: <a href="https://www.cs.ubc.ca/~murphyk/MLbook/">Machine Learning: a Probabilistic Perspective</a>
<ul>
<li>by Kevin Patrick Murphy</li>
</ul></li>
<li><strong>ESL</strong>: <a href="https://web.stanford.edu/~hastie/ElemStatLearn/">The Elements of Statistical Learning:</a>
<ul>
<li>by Trevor Hastie, Robert Tibshirani, and Jerome Friedman</li>
</ul></li>
</ul>
</section><section id="should-i-buy-the-books" class="slide level2">
<h2>Should I buy the books?</h2>
<ul>
<li>You are welcome to buy physical copies if you wish—they’re good books!</li>
<li>But the online versions will suffice for this course.</li>
</ul>
</section></section>
    </div>
  </div>

  <script src="../../assets/custom-js/reveal.js//js/reveal.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        // Push each slide change to the browser history
        history: true,

        // Optional reveal.js plugins
        dependencies: [
          { src: '../../assets/custom-js/reveal.js//lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: '../../assets/custom-js/reveal.js//plugin/zoom-js/zoom.js', async: true },
          { src: '../../assets/custom-js/reveal.js//plugin/notes/notes.js', async: true }
        ]
      });
    </script>
    </body>
</html>
